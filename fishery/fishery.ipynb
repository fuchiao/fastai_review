{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from shutil import rmtree, copyfile\n",
    "\n",
    "labels = [s.split('/')[1] for s in glob('data/*')]\n",
    "rmtree('training', ignore_errors=True)\n",
    "rmtree('validation', ignore_errors=True)\n",
    "random.seed(1024)\n",
    "for label in labels:\n",
    "    jpgs = glob('data/'+label+'/*.jpg')\n",
    "    random.shuffle(jpgs)\n",
    "    l = len(jpgs)//5\n",
    "    os.makedirs('training/'+label)\n",
    "    for jpg in jpgs[l:]:\n",
    "        copyfile(jpg, 'training/'+label+'/'+os.path.basename(jpg))\n",
    "    os.makedirs('validation/'+label)\n",
    "    for jpg in jpgs[:l]:\n",
    "        copyfile(jpg, 'validation/'+label+'/'+os.path.basename(jpg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Lambda, Flatten, Dropout\n",
    "from keras.layers.convolutional import ZeroPadding2D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPaddi (None, 3, 226, 226)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPaddi (None, 64, 226, 226)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPaddi (None, 64, 114, 114)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPaddi (None, 128, 114, 114)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPaddi (None, 128, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPaddi (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPaddi (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPaddi (None, 256, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPaddi (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 32776     \n",
      "=================================================================\n",
      "Total params: 134,326,088\n",
      "Trainable params: 32,776\n",
      "Non-trainable params: 134,293,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG_MEAN = np.array([123.68, 116.779, 103.939]).reshape((3, 1, 1))\n",
    "def preprocessing(img):\n",
    "    img = img - VGG_MEAN\n",
    "    return img\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(preprocessing, input_shape=(3, 224, 224), output_shape=(3, 224, 224)))\n",
    "# Layer 1\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# Layer 3\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# Layer 4\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# Layer 5\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "model.load_weights('vgg16_bn_tf.h5')\n",
    "\n",
    "model.pop()\n",
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def onehot(x):\n",
    "    return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, batch_size=4, class_mode='categorical',\n",
    "                target_size=(224,224)):\n",
    "    return gen.flow_from_directory(dirname, \n",
    "                                   target_size=target_size, \n",
    "                                   class_mode=class_mode, \n",
    "                                   shuffle=shuffle, \n",
    "                                   batch_size=batch_size)\n",
    "def get_data(path, target_size=(224,224)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1, class_mode=None, target_size=target_size)\n",
    "    classes = batches.classes\n",
    "    filenames = batches.filenames\n",
    "    return np.concatenate([batches.next() for i in range(batches.samples)]), classes, onehot(classes), filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3025 images belonging to 8 classes.\n",
      "Found 752 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "training_batches = get_batches('training', batch_size=64)\n",
    "validation_batches = get_batches('validation', batch_size=64*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3025 images belonging to 8 classes.\n",
      "Found 752 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "trn, trn_classes, trn_labels, trn_filenames = get_data('training')\n",
    "val, val_classes, val_labels, val_filenames = get_data('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('trn.dat', trn)\n",
    "save_array('val.dat', val)\n",
    "save_array('trn_labels.dat', trn_labels)\n",
    "save_array('val_labels.dat', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = load_array('trn.dat')\n",
    "val = load_array('val.dat')\n",
    "trn_labels = load_array('trn_labels.dat')\n",
    "val_labels = load_array('val_labels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3025 samples, validate on 752 samples\n",
      "Epoch 1/3\n",
      "3025/3025 [==============================] - 109s - loss: 2.8602 - acc: 0.4707 - val_loss: 1.4336 - val_acc: 0.6609\n",
      "Epoch 2/3\n",
      "3025/3025 [==============================] - 64s - loss: 1.6655 - acc: 0.6440 - val_loss: 0.9854 - val_acc: 0.7646\n",
      "Epoch 3/3\n",
      "3025/3025 [==============================] - 64s - loss: 1.3035 - acc: 0.7005 - val_loss: 0.7049 - val_acc: 0.7992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ef6689080>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn, trn_labels, batch_size=64, epochs=3, validation_data=(val, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('ft1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precompute conv output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = [index for index, layer in enumerate(model.layers) if type(layer) is Conv2D][-1]\n",
    "conv_layers, fc_layers = model.layers[:layer_idx+1], model.layers[layer_idx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = conv_model.predict(trn)\n",
    "conv_val_feat = conv_model.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array('conv_feat.dat', conv_feat)\n",
    "save_array('conv_val_feat.dat', conv_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = load_array('conv_feat.dat')\n",
    "conv_val_feat = load_array('conv_val_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(752, 512, 14, 14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(p/4),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(8, activation='softmax')\n",
    "    ]\n",
    "\n",
    "bn_model = Sequential(get_bn_layers(0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3025 samples, validate on 752 samples\n",
      "Epoch 1/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0958 - acc: 0.9765 - val_loss: 0.1500 - val_acc: 0.9641\n",
      "Epoch 2/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0907 - acc: 0.9775 - val_loss: 0.1359 - val_acc: 0.9721\n",
      "Epoch 3/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0635 - acc: 0.9795 - val_loss: 0.1597 - val_acc: 0.9641\n",
      "Epoch 4/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0673 - acc: 0.9798 - val_loss: 0.1600 - val_acc: 0.9628\n",
      "Epoch 5/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0441 - acc: 0.9871 - val_loss: 0.1612 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0365 - acc: 0.9884 - val_loss: 0.1750 - val_acc: 0.9654\n",
      "Epoch 7/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0368 - acc: 0.9904 - val_loss: 0.1664 - val_acc: 0.9747\n",
      "Epoch 8/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0207 - acc: 0.9950 - val_loss: 0.1777 - val_acc: 0.9721\n",
      "Epoch 9/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0254 - acc: 0.9931 - val_loss: 0.1745 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0202 - acc: 0.9937 - val_loss: 0.1822 - val_acc: 0.9681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ef4707780>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=64, epochs=10, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3025 samples, validate on 752 samples\n",
      "Epoch 1/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0238 - acc: 0.9924 - val_loss: 0.1852 - val_acc: 0.9721\n",
      "Epoch 2/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0208 - acc: 0.9934 - val_loss: 0.1712 - val_acc: 0.9721\n",
      "Epoch 3/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0208 - acc: 0.9947 - val_loss: 0.1564 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0284 - acc: 0.9947 - val_loss: 0.1679 - val_acc: 0.9694\n",
      "Epoch 5/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0328 - acc: 0.9907 - val_loss: 0.1969 - val_acc: 0.9628\n",
      "Epoch 6/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0228 - acc: 0.9940 - val_loss: 0.1624 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0237 - acc: 0.9940 - val_loss: 0.1991 - val_acc: 0.9654\n",
      "Epoch 8/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0135 - acc: 0.9964 - val_loss: 0.2048 - val_acc: 0.9694\n",
      "Epoch 9/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0151 - acc: 0.9960 - val_loss: 0.2215 - val_acc: 0.9654\n",
      "Epoch 10/10\n",
      "3025/3025 [==============================] - 2s - loss: 0.0158 - acc: 0.9950 - val_loss: 0.2056 - val_acc: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ef4707b70>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.optimizer.lr = 1e-4\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=64, epochs=10, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights('conv_512_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights('conv_512_6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi input, add image_size as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1192, 670): 162,\n",
       " (1244, 700): 21,\n",
       " (1276, 718): 184,\n",
       " (1280, 720): 1718,\n",
       " (1280, 750): 485,\n",
       " (1280, 924): 52,\n",
       " (1280, 974): 319,\n",
       " (1334, 750): 25,\n",
       " (1518, 854): 30,\n",
       " (1732, 974): 29}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = [PIL.Image.open('training/'+f).size for f in trn_filenames]\n",
    "id2size = list(set(sizes))\n",
    "size2id = {o:i for i, o in enumerate(id2size)}\n",
    "{i:sizes.count(i) for i in id2size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "trn_sizes_orig = to_categorical([size2id[o] for o in sizes], len(id2size))\n",
    "trn_sizes_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sizes = [PIL.Image.open('validation/'+f).size for f in val_filenames]\n",
    "val_sizes_orig = to_categorical([size2id[o] for o in val_sizes], len(id2size))\n",
    "val_sizes_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1322526 ,  0.5630276 , -0.34334557, ..., -1.14649928,\n",
       "        -0.25449151, -0.10008344],\n",
       "       [-0.1322526 , -0.4369724 , -0.34334557, ..., -0.14649928,\n",
       "        -0.25449151, -0.10008344],\n",
       "       [-0.1322526 , -0.4369724 , -0.34334557, ..., -0.14649928,\n",
       "        -0.25449151, -0.10008344],\n",
       "       ..., \n",
       "       [-0.1322526 , -0.4369724 ,  0.65665443, ..., -1.14649928,\n",
       "        -0.25449151, -0.10008344],\n",
       "       [-0.1322526 , -0.4369724 , -0.34334557, ..., -0.14649928,\n",
       "        -0.25449151, -0.10008344],\n",
       "       [-0.1322526 , -0.4369724 , -0.34334557, ..., -0.14649928,\n",
       "        -0.25449151, -0.10008344]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding, then normalization\n",
    "trn_sizes = trn_sizes_orig - trn_sizes_orig.mean(axis=0) / trn_sizes_orig.std(axis=0)\n",
    "val_sizes = val_sizes_orig - trn_sizes_orig.mean(axis=0) / trn_sizes_orig.std(axis=0)\n",
    "trn_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 512, 14, 14)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D)  (None, 512, 7, 7)     0           input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 512, 7, 7)     2048        max_pooling2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 512, 7, 7)     0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 25088)         0           dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 512)           12845568    flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 512)           2048        dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 512)           0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 512)           262656      dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 512)           2048        dense_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 10)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 512)           0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 10)            40          input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 522)           0           dropout_16[0][0]                 \n",
      "                                                                   batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 8)             4184        concatenate_2[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 13,118,592\n",
      "Trainable params: 13,115,500\n",
      "Non-trainable params: 3,092\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "inp = Input(conv_layers[-1].output_shape[1:])\n",
    "sz_inp = Input((len(id2size),))\n",
    "bn_inp = BatchNormalization()(sz_inp)\n",
    "\n",
    "p = 0.6\n",
    "x = MaxPooling2D()(inp)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(p/4)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x = concatenate([x,bn_inp])\n",
    "x = Dense(8, activation='softmax')(x)\n",
    "\n",
    "model = Model([inp, sz_inp], x)\n",
    "model.summary()\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3025 samples, validate on 752 samples\n",
      "Epoch 1/3\n",
      "3025/3025 [==============================] - 2s - loss: 1.2144 - acc: 0.6489 - val_loss: 1.3346 - val_acc: 0.7926\n",
      "Epoch 2/3\n",
      "3025/3025 [==============================] - 2s - loss: 0.3298 - acc: 0.9048 - val_loss: 0.4542 - val_acc: 0.8963\n",
      "Epoch 3/3\n",
      "3025/3025 [==============================] - 2s - loss: 0.1701 - acc: 0.9554 - val_loss: 0.2007 - val_acc: 0.9428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ee630ef98>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([conv_feat, trn_sizes], trn_labels, batch_size=64, epochs=3, \n",
    "             validation_data=([conv_val_feat, val_sizes], val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3025 samples, validate on 752 samples\n",
      "Epoch 1/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0168 - acc: 0.9960 - val_loss: 0.2403 - val_acc: 0.9601\n",
      "Epoch 2/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0227 - acc: 0.9934 - val_loss: 0.2152 - val_acc: 0.9668\n",
      "Epoch 3/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0119 - acc: 0.9964 - val_loss: 0.2396 - val_acc: 0.9654\n",
      "Epoch 4/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0166 - acc: 0.9957 - val_loss: 0.2375 - val_acc: 0.9654\n",
      "Epoch 5/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0186 - acc: 0.9954 - val_loss: 0.2127 - val_acc: 0.9721\n",
      "Epoch 6/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0225 - acc: 0.9927 - val_loss: 0.2142 - val_acc: 0.9734\n",
      "Epoch 7/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0140 - acc: 0.9937 - val_loss: 0.2203 - val_acc: 0.9694\n",
      "Epoch 8/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0158 - acc: 0.9957 - val_loss: 0.2096 - val_acc: 0.9681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ee627b748>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=64, epochs=8, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3025 samples, validate on 752 samples\n",
      "Epoch 1/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0147 - acc: 0.9954 - val_loss: 0.2072 - val_acc: 0.9707\n",
      "Epoch 2/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0213 - acc: 0.9934 - val_loss: 0.2256 - val_acc: 0.9654\n",
      "Epoch 3/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0213 - acc: 0.9944 - val_loss: 0.1591 - val_acc: 0.9774\n",
      "Epoch 4/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0235 - acc: 0.9934 - val_loss: 0.1973 - val_acc: 0.9721\n",
      "Epoch 5/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0178 - acc: 0.9944 - val_loss: 0.1995 - val_acc: 0.9721\n",
      "Epoch 6/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0136 - acc: 0.9970 - val_loss: 0.1619 - val_acc: 0.9747\n",
      "Epoch 7/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0168 - acc: 0.9934 - val_loss: 0.1866 - val_acc: 0.9734\n",
      "Epoch 8/8\n",
      "3025/3025 [==============================] - 2s - loss: 0.0095 - acc: 0.9964 - val_loss: 0.1937 - val_acc: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ee627ba90>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.optimizer.lr = 1e-4\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=64, epochs=8, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi output, bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
