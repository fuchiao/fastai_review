{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(4)\n",
    "cfg = K.tf.ConfigProto(gpu_options={'allow_growth': True})\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenges = {\n",
    "    # QA1 with 10,000 samples\n",
    "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
    "    # QA2 with 10,000 samples\n",
    "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\n",
    "    'two_supporting_facts_1k': 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt',\n",
    "}\n",
    "challenge_type = 'single_supporting_fact_10k'\n",
    "# challenge_type = 'two_supporting_facts_10k'\n",
    "challenge = challenges[challenge_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/dev/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "def tokenize(sent):\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n",
    "def parse_stories(lines):\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        if int(nid) == 1: story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            substory = [[str(i)+\":\"]+x for i,x in enumerate(story) if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else: story.append(tokenize(line))\n",
    "    return data\n",
    "def get_stories(f):\n",
    "    data = parse_stories(open(f).readlines())\n",
    "    return [(story, q, answer) for story, q, answer in data]\n",
    "\n",
    "train_stories = get_stories(challenge.format('train'))\n",
    "test_stories = get_stories(challenge.format('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = train_stories + test_stories\n",
    "story_maxlen = max((len(s) for x, _, _ in stories for s in x))\n",
    "story_maxsents = max((len(x) for x, _, _ in stories))\n",
    "query_maxlen = max(len(x) for _, x, _ in stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_flatten(el): \n",
    "    return isinstance(el, collections.Iterable) and not isinstance(el, (str, bytes))\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if do_flatten(el): yield from flatten(el)\n",
    "        else: yield el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(flatten(stories)))\n",
    "vocab.insert(0, '<PAD>')\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 8, 4, 10000, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_maxsents, vocab_size, story_maxlen, query_maxlen, len(train_stories), len(test_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['0:', 'Mary', 'moved', 'to', 'the', 'office', '.'],\n",
       "  ['1:', 'John', 'moved', 'to', 'the', 'garden', '.'],\n",
       "  ['3:', 'Sandra', 'moved', 'to', 'the', 'bedroom', '.'],\n",
       "  ['4:', 'Sandra', 'went', 'back', 'to', 'the', 'office', '.'],\n",
       "  ['6:', 'John', 'went', 'to', 'the', 'bedroom', '.'],\n",
       "  ['7:', 'John', 'journeyed', 'to', 'the', 'garden', '.'],\n",
       "  ['9:', 'Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
       "  ['10:', 'John', 'journeyed', 'to', 'the', 'bedroom', '.'],\n",
       "  ['12:', 'Daniel', 'journeyed', 'to', 'the', 'bathroom', '.'],\n",
       "  ['13:', 'John', 'travelled', 'to', 'the', 'garden', '.']],\n",
       " ['Where', 'is', 'Daniel', '?'],\n",
       " 'bathroom')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stories[534]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idx = dict((c, i) for i, c in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    X = []; Xq = []; Y = []\n",
    "    for story, query, answer in data:\n",
    "        x = [[word_idx[w] for w in s] for s in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        y = [word_idx[answer]]\n",
    "        X.append(x); Xq.append(xq); Y.append(y)\n",
    "    return ([pad_sequences(x, maxlen=story_maxlen) for x in X],\n",
    "            pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_inputs(inputs):\n",
    "    for i,it in enumerate(inputs):\n",
    "        inputs[i] = np.concatenate([it, \n",
    "                           np.zeros((story_maxsents-it.shape[0],story_maxlen), 'int')])\n",
    "    return np.stack(inputs)\n",
    "inputs_train = stack_inputs(inputs_train)\n",
    "inputs_test = stack_inputs(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2, 15, 26, 29, 28, 19,  1],\n",
       "       [ 0,  6, 14, 31, 29, 28, 22,  1],\n",
       "       [ 7, 13, 31, 18, 29, 28, 22,  1],\n",
       "       [ 0,  8, 16, 26, 29, 28, 21,  1],\n",
       "       [ 0,  9, 14, 26, 29, 28, 27,  1],\n",
       "       [ 0, 10, 16, 24, 29, 28, 19,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = [inputs_train, queries_train]\n",
    "val_inps = [inputs_test, queries_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Lambda, Input, Reshape, Activation, dot, Dense, add\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_sent_bow(inp):\n",
    "    emb = TimeDistributed(Embedding(vocab_size, emb_dim))(inp)\n",
    "    return Lambda(lambda x: K.sum(x, 2))(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(10), Dimension(8)]),\n",
       " TensorShape([Dimension(None), Dimension(10), Dimension(20)]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_story = Input((story_maxsents, story_maxlen))\n",
    "emb_story = emb_sent_bow(inp_story)\n",
    "inp_story.shape, emb_story.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(4)]),\n",
       " TensorShape([Dimension(None), Dimension(1), Dimension(20)]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_q = Input((query_maxlen,))\n",
    "emb_q = Embedding(vocab_size, emb_dim)(inp_q)\n",
    "emb_q = Lambda(lambda x: K.sum(x, 1))(emb_q)\n",
    "emb_q = Reshape((1, emb_dim))(emb_q)\n",
    "inp_q.shape, emb_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(1)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dot([emb_story, emb_q], axes=2)\n",
    "x = Reshape((story_maxsents,))(x)\n",
    "x = Activation('softmax')(x)\n",
    "match = Reshape((story_maxsents,1))(x)\n",
    "match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_c = emb_sent_bow(inp_story)\n",
    "x = dot([match, emb_c], axes=1)\n",
    "response = Reshape((emb_dim,))(x)\n",
    "res = Dense(vocab_size, activation='softmax')(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Model([inp_story, inp_q], res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/4\n",
      "10000/10000 [==============================] - 13s - loss: 0.3647 - acc: 0.8806 - val_loss: 6.4418e-04 - val_acc: 1.0000\n",
      "Epoch 2/4\n",
      "10000/10000 [==============================] - 1s - loss: 0.0056 - acc: 0.9989 - val_loss: 4.4154e-06 - val_acc: 1.0000\n",
      "Epoch 3/4\n",
      "10000/10000 [==============================] - 1s - loss: 0.0047 - acc: 0.9994 - val_loss: 3.4261e-06 - val_acc: 1.0000\n",
      "Epoch 4/4\n",
      "10000/10000 [==============================] - 1s - loss: 0.0072 - acc: 0.9989 - val_loss: 6.0545e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "K.set_value(answer.optimizer.lr, 1e-2)\n",
    "hist=answer.fit(inps, answers_train, verbose=1, epochs=4, batch_size=32,\n",
    "           validation_data=(val_inps, answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Model([inp_story, inp_q], match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnum=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['0:', 'Sandra', 'travelled', 'to', 'the', 'office', '.'],\n",
       "  ['1:', 'Sandra', 'went', 'to', 'the', 'bathroom', '.'],\n",
       "  ['3:', 'Mary', 'went', 'to', 'the', 'bedroom', '.'],\n",
       "  ['4:', 'Daniel', 'moved', 'to', 'the', 'hallway', '.']],\n",
       " ['Where', 'is', 'Sandra', '?'],\n",
       " 'bathroom')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_st = len(train_stories[qnum][0])+1\n",
    "train_stories[qnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.7585e-03,   9.9301e-01,   2.8352e-06,   2.2931e-04,   3.6505e-12], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(f.predict([inputs_train[qnum:qnum+1], queries_train[qnum:qnum+1]]))[:l_st]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 19, 27, 22, 19, 20, 19, 19, 20, 20])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train[qnum:qnum+10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 19, 27, 22, 19, 20, 19, 19, 20, 20])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(answer.predict([inputs_train[qnum:qnum+10], queries_train[qnum:qnum+10]]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.6171e-13,   2.7784e-13,   1.4070e-13,   4.5004e-13,\n",
       "          2.8679e-13,   1.3773e-13,   8.2310e-14,   2.4749e-13,\n",
       "          3.2073e-13,   4.5508e-13,   4.7181e-13,   1.6863e-13,\n",
       "          1.9341e-13,   1.6086e-13,   1.2592e-13,   2.1884e-13,\n",
       "          5.3411e-13,   1.6679e-13,   2.7770e-13,   1.0000e+00,\n",
       "          3.7796e-10,   1.5543e-11,   6.2230e-13,   1.0592e-13,\n",
       "          4.0973e-13,   1.0297e-10,   2.9755e-13,   1.0429e-13,\n",
       "          6.2321e-13,   3.4418e-13,   9.5986e-13,   2.3595e-13]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.predict([inputs_train[qnum:qnum+1], queries_train[qnum:qnum+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bathroom'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multihop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_type = 'two_supporting_facts_10k'\n",
    "challenge = challenges[challenge_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/dev/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "train_stories = get_stories(challenge.format('train'))\n",
    "test_stories = get_stories(challenge.format('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['0:', 'Mary', 'went', 'to', 'the', 'hallway', '.'],\n",
       "  ['1:', 'Daniel', 'went', 'back', 'to', 'the', 'bedroom', '.'],\n",
       "  ['2:', 'Sandra', 'went', 'back', 'to', 'the', 'garden', '.'],\n",
       "  ['3:', 'Mary', 'went', 'to', 'the', 'office', '.'],\n",
       "  ['4:', 'Mary', 'journeyed', 'to', 'the', 'kitchen', '.'],\n",
       "  ['5:', 'Sandra', 'moved', 'to', 'the', 'office', '.'],\n",
       "  ['6:', 'Sandra', 'journeyed', 'to', 'the', 'hallway', '.'],\n",
       "  ['7:', 'Daniel', 'journeyed', 'to', 'the', 'garden', '.'],\n",
       "  ['8:', 'Mary', 'journeyed', 'to', 'the', 'bathroom', '.'],\n",
       "  ['9:', 'John', 'went', 'back', 'to', 'the', 'bathroom', '.'],\n",
       "  ['10:', 'Sandra', 'travelled', 'to', 'the', 'garden', '.'],\n",
       "  ['11:', 'John', 'moved', 'to', 'the', 'office', '.'],\n",
       "  ['12:', 'Daniel', 'went', 'back', 'to', 'the', 'kitchen', '.'],\n",
       "  ['13:', 'Mary', 'moved', 'to', 'the', 'kitchen', '.'],\n",
       "  ['14:', 'Mary', 'moved', 'to', 'the', 'hallway', '.'],\n",
       "  ['15:', 'Mary', 'went', 'to', 'the', 'kitchen', '.'],\n",
       "  ['16:', 'Sandra', 'went', 'back', 'to', 'the', 'bedroom', '.'],\n",
       "  ['17:', 'Sandra', 'travelled', 'to', 'the', 'hallway', '.'],\n",
       "  ['18:', 'Sandra', 'travelled', 'to', 'the', 'kitchen', '.'],\n",
       "  ['19:', 'Sandra', 'moved', 'to', 'the', 'garden', '.'],\n",
       "  ['20:', 'Daniel', 'went', 'to', 'the', 'garden', '.'],\n",
       "  ['21:', 'Sandra', 'went', 'back', 'to', 'the', 'bathroom', '.'],\n",
       "  ['22:', 'John', 'moved', 'to', 'the', 'garden', '.'],\n",
       "  ['23:', 'Mary', 'went', 'to', 'the', 'bathroom', '.'],\n",
       "  ['24:', 'Daniel', 'travelled', 'to', 'the', 'kitchen', '.'],\n",
       "  ['25:', 'John', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
       "  ['26:', 'Sandra', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
       "  ['27:', 'Mary', 'went', 'to', 'the', 'hallway', '.'],\n",
       "  ['28:', 'Daniel', 'went', 'back', 'to', 'the', 'garden', '.'],\n",
       "  ['29:', 'Sandra', 'went', 'back', 'to', 'the', 'office', '.'],\n",
       "  ['30:', 'Sandra', 'moved', 'to', 'the', 'kitchen', '.'],\n",
       "  ['31:', 'Mary', 'travelled', 'to', 'the', 'garden', '.'],\n",
       "  ['32:', 'Sandra', 'went', 'to', 'the', 'garden', '.'],\n",
       "  ['33:', 'Daniel', 'journeyed', 'to', 'the', 'hallway', '.'],\n",
       "  ['34:', 'Mary', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
       "  ['35:', 'Daniel', 'travelled', 'to', 'the', 'garden', '.'],\n",
       "  ['36:', 'John', 'journeyed', 'to', 'the', 'bathroom', '.'],\n",
       "  ['37:', 'Daniel', 'travelled', 'to', 'the', 'hallway', '.'],\n",
       "  ['38:', 'Daniel', 'travelled', 'to', 'the', 'bedroom', '.'],\n",
       "  ['39:', 'Mary', 'went', 'back', 'to', 'the', 'kitchen', '.'],\n",
       "  ['40:', 'Daniel', 'went', 'to', 'the', 'office', '.'],\n",
       "  ['41:', 'John', 'journeyed', 'to', 'the', 'hallway', '.'],\n",
       "  ['42:', 'John', 'went', 'to', 'the', 'kitchen', '.'],\n",
       "  ['43:', 'Daniel', 'travelled', 'to', 'the', 'hallway', '.'],\n",
       "  ['44:', 'Sandra', 'went', 'back', 'to', 'the', 'kitchen', '.'],\n",
       "  ['45:', 'Mary', 'moved', 'to', 'the', 'office', '.'],\n",
       "  ['46:', 'Sandra', 'went', 'back', 'to', 'the', 'garden', '.'],\n",
       "  ['47:', 'Sandra', 'went', 'back', 'to', 'the', 'kitchen', '.'],\n",
       "  ['48:', 'Sandra', 'moved', 'to', 'the', 'garden', '.'],\n",
       "  ['49:', 'Sandra', 'moved', 'to', 'the', 'office', '.'],\n",
       "  ['50:', 'John', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
       "  ['51:', 'Daniel', 'went', 'to', 'the', 'garden', '.'],\n",
       "  ['52:', 'Sandra', 'travelled', 'to', 'the', 'kitchen', '.'],\n",
       "  ['53:', 'Sandra', 'moved', 'to', 'the', 'bathroom', '.'],\n",
       "  ['54:', 'John', 'journeyed', 'to', 'the', 'garden', '.'],\n",
       "  ['55:', 'Mary', 'moved', 'to', 'the', 'hallway', '.'],\n",
       "  ['56:', 'John', 'went', 'back', 'to', 'the', 'office', '.'],\n",
       "  ['57:', 'Mary', 'went', 'back', 'to', 'the', 'office', '.'],\n",
       "  ['58:', 'Daniel', 'travelled', 'to', 'the', 'bathroom', '.'],\n",
       "  ['59:', 'Sandra', 'travelled', 'to', 'the', 'hallway', '.'],\n",
       "  ['60:', 'Sandra', 'journeyed', 'to', 'the', 'bathroom', '.'],\n",
       "  ['61:', 'Sandra', 'travelled', 'to', 'the', 'bedroom', '.'],\n",
       "  ['62:', 'Mary', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
       "  ['63:', 'Sandra', 'travelled', 'to', 'the', 'kitchen', '.'],\n",
       "  ['64:', 'Daniel', 'travelled', 'to', 'the', 'garden', '.'],\n",
       "  ['65:', 'Daniel', 'journeyed', 'to', 'the', 'bedroom', '.'],\n",
       "  ['66:', 'Mary', 'journeyed', 'to', 'the', 'office', '.'],\n",
       "  ['67:', 'Sandra', 'went', 'back', 'to', 'the', 'office', '.'],\n",
       "  ['68:', 'John', 'travelled', 'to', 'the', 'hallway', '.'],\n",
       "  ['69:', 'Daniel', 'picked', 'up', 'the', 'milk', 'there', '.'],\n",
       "  ['70:', 'Daniel', 'picked', 'up', 'the', 'apple', 'there', '.'],\n",
       "  ['71:', 'Sandra', 'moved', 'to', 'the', 'hallway', '.'],\n",
       "  ['72:', 'John', 'journeyed', 'to', 'the', 'bedroom', '.'],\n",
       "  ['73:', 'John', 'went', 'back', 'to', 'the', 'garden', '.'],\n",
       "  ['74:', 'Sandra', 'journeyed', 'to', 'the', 'office', '.'],\n",
       "  ['75:', 'Sandra', 'moved', 'to', 'the', 'bedroom', '.'],\n",
       "  ['76:', 'Mary', 'moved', 'to', 'the', 'kitchen', '.'],\n",
       "  ['77:', 'Mary', 'went', 'to', 'the', 'office', '.'],\n",
       "  ['78:', 'Sandra', 'grabbed', 'the', 'football', 'there', '.'],\n",
       "  ['79:', 'Sandra', 'discarded', 'the', 'football', '.'],\n",
       "  ['81:', 'Daniel', 'took', 'the', 'football', 'there', '.'],\n",
       "  ['82:', 'Daniel', 'put', 'down', 'the', 'apple', 'there', '.'],\n",
       "  ['84:', 'Daniel', 'took', 'the', 'apple', 'there', '.'],\n",
       "  ['85:', 'Daniel', 'travelled', 'to', 'the', 'hallway', '.'],\n",
       "  ['87:', 'Sandra', 'journeyed', 'to', 'the', 'bathroom', '.'],\n",
       "  ['88:', 'Daniel', 'left', 'the', 'milk', 'there', '.'],\n",
       "  ['90:', 'Daniel', 'went', 'to', 'the', 'kitchen', '.'],\n",
       "  ['91:', 'Daniel', 'went', 'back', 'to', 'the', 'bathroom', '.']],\n",
       " ['Where', 'is', 'the', 'milk', '?'],\n",
       " 'hallway')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stories[534]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 88, 8), (1000, 88, 8))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories = train_stories + test_stories\n",
    "story_maxlen = max((len(s) for x, _, _ in stories for s in x))\n",
    "story_maxsents = max((len(x) for x, _, _ in stories))\n",
    "query_maxlen = max(len(x) for _, x, _ in stories)\n",
    "\n",
    "vocab = sorted(set(flatten(stories)))\n",
    "vocab.insert(0, '<PAD>')\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_idx = dict((c, i) for i, c in enumerate(vocab))\n",
    "\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)\n",
    "\n",
    "inputs_train = stack_inputs(inputs_train)\n",
    "inputs_test = stack_inputs(inputs_test)\n",
    "\n",
    "inps = [inputs_train, queries_train]\n",
    "val_inps = [inputs_test, queries_test]\n",
    "\n",
    "inputs_train.shape, inputs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_sent_bow(inp):\n",
    "    emb_op = TimeDistributed(Embedding(vocab_size, emb_dim))\n",
    "    emb = emb_op(inp)\n",
    "    emb = Lambda(lambda x: K.sum(x, 2))(emb)\n",
    "    return Elemwise(0, False)(emb), emb_op\n",
    "#    return emb, emb_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_story = Input((story_maxsents, story_maxlen))\n",
    "inp_q = Input((query_maxlen,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_story, emb_story_op = emb_sent_bow(inp_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_q = emb_story_op.layer(inp_q)\n",
    "emb_q = Lambda(lambda x: K.sum(x, 1))(emb_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Dense(emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hop(u, A):\n",
    "    C, _ = emb_sent_bow(inp_story)\n",
    "    x = Reshape((1, emb_dim))(u)\n",
    "    x = dot([A, x], axes=2)\n",
    "    x = Reshape((story_maxsents,))(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    match = Reshape((story_maxsents,1))(x)\n",
    "\n",
    "    x = dot([match, C], axes=1)\n",
    "    x = Reshape((emb_dim,))(x)\n",
    "    x = h(x)\n",
    "    x = add([x, emb_q])\n",
    "    return x, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, emb_story = one_hop(emb_q, emb_story)\n",
    "response, emb_story = one_hop(response, emb_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Dense(vocab_size, activation='softmax')(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Model([inp_story, inp_q], res)\n",
    "answer.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 88, 8)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 5)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistrib (None, 88, 8, 30)     3720        input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)         (None, 5, 30)         3720        input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)               (None, 88, 30)        0           time_distributed_17[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)               (None, 30)            0           embedding_19[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "elemwise_9 (Elemwise)            (None, 88, 30)        88          lambda_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)             (None, 1, 30)         0           lambda_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dot_7 (Dot)                      (None, 88, 1)         0           elemwise_9[0][0]                 \n",
      "                                                                   reshape_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistrib (None, 88, 8, 30)     3720        input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)             (None, 88)            0           dot_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)               (None, 88, 30)        0           time_distributed_18[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 88)            0           reshape_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "elemwise_10 (Elemwise)           (None, 88, 30)        88          lambda_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)             (None, 88, 1)         0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dot_8 (Dot)                      (None, 1, 30)         0           reshape_17[0][0]                 \n",
      "                                                                   elemwise_10[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)             (None, 30)            0           dot_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 30)            930         reshape_18[0][0]                 \n",
      "                                                                   reshape_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 30)            0           dense_4[0][0]                    \n",
      "                                                                   lambda_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)             (None, 1, 30)         0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dot_9 (Dot)                      (None, 88, 1)         0           elemwise_10[0][0]                \n",
      "                                                                   reshape_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)             (None, 88)            0           dot_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistrib (None, 88, 8, 30)     3720        input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 88)            0           reshape_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)               (None, 88, 30)        0           time_distributed_19[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)             (None, 88, 1)         0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "elemwise_11 (Elemwise)           (None, 88, 30)        88          lambda_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dot_10 (Dot)                     (None, 1, 30)         0           reshape_21[0][0]                 \n",
      "                                                                   elemwise_11[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)             (None, 30)            0           dot_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 30)            0           dense_4[1][0]                    \n",
      "                                                                   lambda_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 124)           3844        add_4[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 16,198\n",
      "Trainable params: 16,198\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "answer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "10000/10000 [==============================] - 3s - loss: 1.7990 - acc: 0.2223 - val_loss: 1.6347 - val_acc: 0.3100\n",
      "Epoch 2/8\n",
      "10000/10000 [==============================] - 2s - loss: 1.2486 - acc: 0.5083 - val_loss: 0.8107 - val_acc: 0.6780\n",
      "Epoch 3/8\n",
      "10000/10000 [==============================] - 2s - loss: 0.6958 - acc: 0.7477 - val_loss: 0.6719 - val_acc: 0.7640\n",
      "Epoch 4/8\n",
      "10000/10000 [==============================] - 2s - loss: 0.6004 - acc: 0.7967 - val_loss: 0.6423 - val_acc: 0.7940\n",
      "Epoch 5/8\n",
      "10000/10000 [==============================] - 2s - loss: 0.5358 - acc: 0.8207 - val_loss: 0.6272 - val_acc: 0.8040\n",
      "Epoch 6/8\n",
      "10000/10000 [==============================] - 2s - loss: 0.4694 - acc: 0.8514 - val_loss: 0.5405 - val_acc: 0.8260\n",
      "Epoch 7/8\n",
      "10000/10000 [==============================] - 2s - loss: 0.4427 - acc: 0.8640 - val_loss: 0.5350 - val_acc: 0.8330\n",
      "Epoch 8/8\n",
      "10000/10000 [==============================] - 2s - loss: 0.4188 - acc: 0.8797 - val_loss: 0.5517 - val_acc: 0.8250\n"
     ]
    }
   ],
   "source": [
    "K.set_value(answer.optimizer.lr, 5e-3)\n",
    "hist=answer.fit(inps, answers_train, verbose=1, epochs=8, batch_size=32,\n",
    "           validation_data=(val_inps, answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31 ,  0.678,  0.764,  0.794,  0.804,  0.826,  0.833,  0.825])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(hist.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elemwise(Layer):\n",
    "    def __init__(self, axis, is_mult, init='glorot_uniform', **kwargs):\n",
    "        self.init = initializers.get(init)\n",
    "        self.axis = axis\n",
    "        self.is_mult = is_mult\n",
    "        super(Elemwise, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dims = input_shape[1:]\n",
    "        dims = [1] * len(input_dims)\n",
    "        dims[self.axis] = input_dims[self.axis]\n",
    "        self.b = self.add_weight(name='{}_bo'.format(self.name),\n",
    "                                 shape=dims,\n",
    "                                 initializer=self.init,)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return x * self.b if self.is_mult else x + self.b\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'init': self.init.__name__, 'axis': self.axis}\n",
    "        base_config = super(Dense, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
